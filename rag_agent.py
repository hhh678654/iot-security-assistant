# rag_agent.py - ä»»åŠ¡åˆ†ç±»ï¼Œä¸­æ¢Agent
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import re

# å¯¼å…¥Ollamaå®¢æˆ·ç«¯
from ollama_client import OllamaClient, OllamaResponse

# å¯¼å…¥å·²æœ‰çš„RAGç³»ç»Ÿ
try:
    from rag_preprocessing import HybridRAGSystem
    from prompt_templates import PromptTemplateManager
except ImportError:
    print("âš ï¸ æœªæ‰¾åˆ°RAGæˆ–Promptæ¨¡å—ï¼Œå°†ä½¿ç”¨ç®€åŒ–æ¨¡å¼")
    HybridRAGSystem = None
    PromptTemplateManager = None


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    CVE_LOOKUP = "cve_lookup"
    THREAT_DETECTION = "threat_detection"
    SECURITY_ASSESSMENT = "security_assessment"
    PREVENTION_ADVICE = "prevention_advice"
    RESEARCH_SUMMARY = "research_summary"
    VULNERABILITY_ANALYSIS = "vulnerability_analysis"
    GENERAL_QUERY = "general_query"


@dataclass
class SimpleAgentResponse:
    """Agentå“åº”"""
    content: str
    confidence: float
    sources: List[Dict]
    task_type: str
    processing_time: float
    model_used: str
    metadata: Dict


class SimpleRAGAgent:
    """RAG+Ollama Agent"""

    def __init__(self, config: Dict = None):
        self.config = config or self._get_default_config()
        self.logger = self._setup_logger()

        # åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
        self.ollama_client = OllamaClient(
            model_name=self.config.get("model_name", "llama3.1:7b"),
            base_url=self.config.get("base_url", "http://localhost:11434"),
            timeout=self.config.get("timeout", 60)
        )

        # åˆå§‹åŒ–RAGç³»ç»Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.rag_system = None
        self.documents = None
        self._initialize_rag_system()

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_queries": 0,
            "successful_responses": 0,
            "rag_searches": 0,
            "average_confidence": 0.0
        }

    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "model_name": "llama3.1:7b",
            "base_url": "http://localhost:11434",
            "timeout": 60,
            "max_tokens": 2000,
            "temperature": 0.7,
            "use_rag": True,
            "rag_top_k": 5,
            "base_dir": "."
        }

    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger("SimpleRAGAgent")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def _initialize_rag_system(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        if not self.config.get("use_rag", True):
            self.logger.info("RAGç³»ç»Ÿå·²ç¦ç”¨")
            return

        try:
            if HybridRAGSystem is None:
                self.logger.warning("RAGç³»ç»Ÿä¸å¯ç”¨ï¼Œå°†åœ¨ç®€åŒ–æ¨¡å¼ä¸‹è¿è¡Œ")
                return

            # åˆå§‹åŒ–RAGç³»ç»Ÿ
            rag_config = {
                'embedding_model': 'all-MiniLM-L6-v2',
                'top_k': self.config.get('rag_top_k', 5),
                'hybrid_alpha': 0.7
            }

            self.rag_system = HybridRAGSystem(rag_config)

            # åŠ è½½é¢„å»ºç´¢å¼•
            self._load_rag_indices()

            if self.documents:
                self.logger.info(f"RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼ŒåŠ è½½äº† {len(self.documents)} ä¸ªæ–‡æ¡£")
            else:
                self.logger.warning("RAGç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åœ¨æ— çŸ¥è¯†åº“æ¨¡å¼ä¸‹è¿è¡Œ")

        except Exception as e:
            self.logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag_system = None
            self.documents = None

    def _load_rag_indices(self):
        """åŠ è½½RAGç´¢å¼•"""
        try:
            import faiss
            import pickle
            from pathlib import Path

            base_dir = Path(self.config.get('base_dir', '.'))
            index_dir = base_dir / "rag_indices"

            # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = [
                "indexed_documents.json",
                "semantic_index.faiss",
                "tfidf_matrix.pkl",
                "tfidf_vectorizer.pkl"
            ]

            missing_files = []
            for file in required_files:
                if not (index_dir / file).exists():
                    missing_files.append(file)

            if missing_files:
                self.logger.warning(f"RAGç´¢å¼•æ–‡ä»¶ç¼ºå¤±: {missing_files}")
                return

            # åŠ è½½æ–‡æ¡£
            with open(index_dir / "indexed_documents.json", 'r', encoding='utf-8') as f:
                self.documents = json.load(f)

            # åŠ è½½è¯­ä¹‰ç´¢å¼•
            self.semantic_index = faiss.read_index(str(index_dir / "semantic_index.faiss"))

            # åŠ è½½TF-IDFç›¸å…³æ•°æ®
            with open(index_dir / "tfidf_matrix.pkl", 'rb') as f:
                self.tfidf_matrix = pickle.load(f)

            with open(index_dir / "tfidf_vectorizer.pkl", 'rb') as f:
                self.rag_system.tfidf_vectorizer = pickle.load(f)

        except Exception as e:
            self.logger.error(f"RAGç´¢å¼•åŠ è½½å¤±è´¥: {e}")
            self.documents = None

    def classify_task(self, user_input: str) -> TaskType:
        """ç®€å•çš„ä»»åŠ¡åˆ†ç±»"""
        user_input_lower = user_input.lower()

        if any(keyword in user_input_lower for keyword in ['cve-', 'vulnerability', 'æ¼æ´']):
            return TaskType.CVE_LOOKUP
        elif any(keyword in user_input_lower for keyword in ['attack', 'threat', 'å¨èƒ', 'æ”»å‡»']):
            return TaskType.THREAT_DETECTION
        elif any(keyword in user_input_lower for keyword in ['assessment', 'risk', 'é£é™©', 'è¯„ä¼°']):
            return TaskType.SECURITY_ASSESSMENT
        elif any(keyword in user_input_lower for keyword in ['prevention', 'protect', 'é˜²æŠ¤', 'ç¼“è§£']):
            return TaskType.PREVENTION_ADVICE
        elif any(keyword in user_input_lower for keyword in ['research', 'summary', 'ç ”ç©¶', 'æ€»ç»“']):
            return TaskType.RESEARCH_SUMMARY
        elif any(keyword in user_input_lower for keyword in ['analyze', 'analysis', 'åˆ†æ']):
            return TaskType.VULNERABILITY_ANALYSIS
        else:
            return TaskType.GENERAL_QUERY

    def search_knowledge(self, query: str, task_type: TaskType) -> List[Dict]:
        """æœç´¢ç›¸å…³çŸ¥è¯†"""
        if not self.rag_system or not self.documents:
            return []

        try:
            # æ‰§è¡Œæ··åˆæ£€ç´¢
            results = self.rag_system.hybrid_search(
                query=query,
                semantic_index=self.semantic_index,
                tfidf_matrix=self.tfidf_matrix,
                documents=self.documents,
                top_k=self.config.get('rag_top_k', 5),
                alpha=0.7
            )

            self.stats["rag_searches"] += 1
            self.logger.info(f"æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
            return results

        except Exception as e:
            self.logger.error(f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {e}")
            return []

    def create_prompt(self, user_input: str, task_type: TaskType, retrieved_docs: List[Dict]) -> str:
        """åˆ›å»ºç®€åŒ–çš„æç¤º"""

        # åŸºç¡€æç¤ºæ¨¡æ¿
        base_prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„IoTå®‰å…¨ä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_input}

ä»»åŠ¡ç±»å‹ï¼š{task_type.value}
"""

        # æ·»åŠ æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        if retrieved_docs:
            context_parts = []
            for i, doc in enumerate(retrieved_docs[:], 1):  # ä½¿ç”¨çš„æ–‡æ¡£æ•°é‡
                source_type = "å­¦æœ¯ç ”ç©¶" if doc['source_type'] == 'academic' else "CVEæ¼æ´æ•°æ®"

                context_part = f"å‚è€ƒèµ„æ–™ {i} ({source_type}):\n"

                # æ·»åŠ å…ƒæ•°æ®
                if doc['source_type'] == 'cve':
                    metadata = doc.get('metadata', {})
                    context_part += f"CVE ID: {metadata.get('cve_id', 'N/A')}\n"
                    context_part += f"ä¸¥é‡ç¨‹åº¦: {metadata.get('severity', 'N/A')}\n"
                elif doc['source_type'] == 'academic':
                    metadata = doc.get('metadata', {})
                    context_part += f"ç ”ç©¶é¢†åŸŸ: {metadata.get('label', 'N/A')}\n"

                # æ·»åŠ æ–‡æ¡£å†…å®¹
                text = doc.get('text', '')
                preview = text[:400] + "..." if len(text) > 400 else text
                context_part += f"å†…å®¹: {preview}\n"

                context_parts.append(context_part)

            context = "\n".join(context_parts)
            base_prompt += f"\nå‚è€ƒä¿¡æ¯ï¼š\n{context}\n"
        else:
            base_prompt += "\nå‚è€ƒä¿¡æ¯ï¼šæ— ç›¸å…³æŠ€æœ¯æ–‡æ¡£ã€‚\n"

        # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ ç‰¹å®šæŒ‡å¯¼
        task_instructions = {
            TaskType.CVE_LOOKUP: """
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åˆ†æCVEæ¼æ´ï¼š
1. æ¼æ´æ¦‚è¿°å’ŒåŸºæœ¬ä¿¡æ¯
2. æŠ€æœ¯ç»†èŠ‚å’Œå½±å“åˆ†æ
3. é£é™©è¯„ä¼°å’Œä¸¥é‡ç¨‹åº¦
4. ç¼“è§£æªæ–½å’Œå»ºè®®""",

            TaskType.THREAT_DETECTION: """
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åˆ†æå¨èƒï¼š
1. å¨èƒè¯†åˆ«å’Œåˆ†ç±»
2. æ”»å‡»å‘é‡å’Œæ‰‹æ®µ
3. å½±å“èŒƒå›´è¯„ä¼°
4. æ£€æµ‹å’Œåº”å¯¹ç­–ç•¥""",

            TaskType.SECURITY_ASSESSMENT: """
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œå®‰å…¨è¯„ä¼°ï¼š
1. å½“å‰å®‰å…¨çŠ¶å†µåˆ†æ
2. æ½œåœ¨é£é™©è¯†åˆ«
3. å®‰å…¨æ§åˆ¶è¯„ä¼°
4. æ”¹è¿›å»ºè®®å’Œä¼˜å…ˆçº§""",

            TaskType.PREVENTION_ADVICE: """
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„æä¾›é˜²æŠ¤å»ºè®®ï¼š
1. é˜²æŠ¤ç›®æ ‡æ˜ç¡®
2. åˆ†å±‚é˜²æŠ¤ç­–ç•¥
3. å…·ä½“æŠ€æœ¯æªæ–½
4. å®æ–½æ­¥éª¤å’Œæ³¨æ„äº‹é¡¹""",

            TaskType.RESEARCH_SUMMARY: """
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„æ€»ç»“ç ”ç©¶ï¼š
1. ç ”ç©¶èƒŒæ™¯å’Œç›®æ ‡
2. ä¸»è¦å‘ç°å’Œåˆ›æ–°ç‚¹
3. æŠ€æœ¯è¶‹åŠ¿åˆ†æ
4. å®é™…åº”ç”¨ä»·å€¼""",

            TaskType.VULNERABILITY_ANALYSIS: """
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åˆ†ææ¼æ´ï¼š
1. æ¼æ´åŸç†å’Œæˆå› 
2. åˆ©ç”¨æ–¹å¼å’Œæ¡ä»¶
3. å½±å“è¯„ä¼°
4. ä¿®å¤å’Œé˜²æŠ¤æ–¹æ¡ˆ""",

            TaskType.GENERAL_QUERY: """
è¯·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€å®ç”¨çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥å›ç­”æ ¸å¿ƒé—®é¢˜
2. ç›¸å…³æŠ€æœ¯è§£é‡Š
3. å®è·µå»ºè®®
4. è¿›ä¸€æ­¥å­¦ä¹ èµ„æº"""
        }

        instruction = task_instructions.get(task_type, task_instructions[TaskType.GENERAL_QUERY])
        base_prompt += f"\nå›ç­”è¦æ±‚ï¼š{instruction}\n"

        base_prompt += """
è¯·ç¡®ä¿å›ç­”ï¼š
- åŸºäºæä¾›çš„å‚è€ƒä¿¡æ¯
- ä¸“ä¸šå‡†ç¡®ï¼Œæ˜“äºç†è§£
- å…·æœ‰å®é™…æ“ä½œä»·å€¼
- é€‚åˆIoTå®‰å…¨ç¯å¢ƒç‰¹ç‚¹

ç°åœ¨è¯·å¼€å§‹å›ç­”ï¼š"""

        return base_prompt

    def generate_response(self, prompt: str, task_type: TaskType) -> OllamaResponse:
        """ä½¿ç”¨Ollamaç”Ÿæˆå“åº”"""
        try:
            return self.ollama_client.generate(
                prompt=prompt,
                max_tokens=self.config.get("max_tokens", 2000),
                temperature=self.config.get("temperature", 0.7)
            )
        except Exception as e:
            self.logger.error(f"Ollamaå“åº”ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def calculate_confidence(self, response: OllamaResponse, retrieved_docs: List[Dict],
                             task_type: TaskType) -> float:
        """è®¡ç®—å“åº”ç½®ä¿¡åº¦"""
        factors = []

        # 1. åŸºäºæ£€ç´¢æ–‡æ¡£è´¨é‡ (40%)
        if retrieved_docs:
            avg_score = sum(doc.get('hybrid_score', 0) for doc in retrieved_docs) / len(retrieved_docs)
            factors.append(avg_score * 0.4)
        else:
            factors.append(0.2)  # æ— æ£€ç´¢æ–‡æ¡£æ—¶çš„åŸºç¡€åˆ†æ•°

        # 2. åŸºäºå“åº”é•¿åº¦å’Œç»“æ„ (30%)
        content_length = len(response.content)
        if content_length > 800:
            length_score = 0.9
        elif content_length > 400:
            length_score = 0.8
        elif content_length > 200:
            length_score = 0.7
        else:
            length_score = 0.5
        factors.append(length_score * 0.3)

        # 3. åŸºäºå†…å®¹è´¨é‡æŒ‡æ ‡ (20%)
        content = response.content.lower()
        quality_indicators = [
            ("å»ºè®®" in content or "recommendation" in content),
            ("åˆ†æ" in content or "analysis" in content),
            ("å®‰å…¨" in content or "security" in content),
            ("iot" in content or "ç‰©è”ç½‘" in content),
            len(re.findall(r'[.ã€‚]', content)) > 5  # å¥å­æ•°é‡
        ]
        quality_score = sum(quality_indicators) / len(quality_indicators)
        factors.append(quality_score * 0.2)

        # 4. åŸºäºä»»åŠ¡åŒ¹é…åº¦ (10%)
        task_keywords = {
            TaskType.CVE_LOOKUP: ["cve", "æ¼æ´", "vulnerability", "cvss"],
            TaskType.THREAT_DETECTION: ["å¨èƒ", "æ”»å‡»", "threat", "attack"],
            TaskType.SECURITY_ASSESSMENT: ["è¯„ä¼°", "é£é™©", "assessment", "risk"],
            TaskType.PREVENTION_ADVICE: ["é˜²æŠ¤", "å»ºè®®", "prevention", "protect"],
            TaskType.RESEARCH_SUMMARY: ["ç ”ç©¶", "æ€»ç»“", "research", "study"],
            TaskType.VULNERABILITY_ANALYSIS: ["åˆ†æ", "åŸç†", "analysis", "mechanism"]
        }

        keywords = task_keywords.get(task_type, [])
        if keywords:
            matches = sum(1 for keyword in keywords if keyword in content)
            task_match_score = min(matches / len(keywords), 1.0)
        else:
            task_match_score = 0.5
        factors.append(task_match_score * 0.1)

        confidence = sum(factors)
        return min(confidence, 0.95)  # æœ€å¤§ç½®ä¿¡åº¦é™åˆ¶

    def extract_recommendations(self, content: str) -> List[str]:
        """æå–å»ºè®®åˆ—è¡¨"""
        recommendations = []

        # æŸ¥æ‰¾å»ºè®®ç›¸å…³çš„æ¨¡å¼
        patterns = [
            r'å»ºè®®[:ï¼š]\s*(.+?)(?=\n\n|\n[0-9]|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]|$)',
            r'æ¨è[:ï¼š]\s*(.+?)(?=\n\n|\n[0-9]|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]|$)',
            r'æªæ–½[:ï¼š]\s*(.+?)(?=\n\n|\n[0-9]|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]|$)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)
            for match in matches:
                # åˆ†å‰²æˆå•ç‹¬çš„å»ºè®®é¡¹
                items = re.split(r'\n[0-9]\.|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]\.|\n[-*â€¢]\s*', match.strip())
                for item in items:
                    clean_item = item.strip().replace('\n', ' ')
                    if clean_item and len(clean_item) > 10:
                        recommendations.append(clean_item)

        # å¦‚æœæ²¡æ‰¾åˆ°æ˜ç¡®çš„å»ºè®®ï¼ŒæŸ¥æ‰¾ç¼–å·åˆ—è¡¨
        if not recommendations:
            numbered_items = re.findall(r'^[0-9]+\.(.+)', content, re.MULTILINE)
            recommendations.extend([item.strip() for item in numbered_items if len(item.strip()) > 15])

        return recommendations[:8]  # é™åˆ¶æ•°é‡

    def prepare_sources(self, retrieved_docs: List[Dict]) -> List[Dict]:
        """å‡†å¤‡æºæ–‡æ¡£ä¿¡æ¯"""
        sources = []

        for doc in retrieved_docs[:10]:  # æœ€å¤š10ä¸ªæº
            source = {
                "id": doc.get('id'),
                "type": doc.get('source_type'),
                "score": round(doc.get('hybrid_score', 0), 3),
                "preview": doc.get('text', '')[:120] + "..."
            }

            if doc.get('source_type') == 'cve':
                metadata = doc.get('metadata', {})
                source.update({
                    "cve_id": metadata.get('cve_id'),
                    "severity": metadata.get('severity'),
                    "cvss_score": metadata.get('base_score')
                })
            elif doc.get('source_type') == 'academic':
                metadata = doc.get('metadata', {})
                source.update({
                    "research_area": metadata.get('label'),
                    "year": metadata.get('year')
                })

            sources.append(source)

        return sources

    def process_query(self, user_input: str) -> SimpleAgentResponse:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„ä¸»æµç¨‹"""
        start_time = time.time()

        try:
            self.stats["total_queries"] += 1
            self.logger.info(f"å¤„ç†æŸ¥è¯¢: {user_input}")

            # 1. ä»»åŠ¡åˆ†ç±»
            task_type = self.classify_task(user_input)
            self.logger.info(f"ä»»åŠ¡ç±»å‹: {task_type.value}")

            # 2. çŸ¥è¯†æ£€ç´¢
            retrieved_docs = self.search_knowledge(user_input, task_type)

            # 3. åˆ›å»ºæç¤º
            prompt = self.create_prompt(user_input, task_type, retrieved_docs)

            # 4. ç”Ÿæˆå“åº”
            ollama_response = self.generate_response(prompt, task_type)

            # 5. è®¡ç®—ç½®ä¿¡åº¦
            confidence = self.calculate_confidence(ollama_response, retrieved_docs, task_type)

            # 6. æå–å»ºè®®
            recommendations = self.extract_recommendations(ollama_response.content)

            # 7. å‡†å¤‡æºä¿¡æ¯
            sources = self.prepare_sources(retrieved_docs)

            # 8. åˆ›å»ºæœ€ç»ˆå“åº”
            processing_time = time.time() - start_time

            response = SimpleAgentResponse(
                content=ollama_response.content,
                confidence=confidence,
                sources=sources,
                task_type=task_type.value,
                processing_time=processing_time,
                model_used=ollama_response.model,
                metadata={
                    "rag_docs_found": len(retrieved_docs),
                    "recommendations_count": len(recommendations),
                    "tokens_used": ollama_response.tokens_used,
                    "llm_response_time": ollama_response.response_time,
                    "timestamp": datetime.now().isoformat()
                }
            )

            # 9. æ›´æ–°ç»Ÿè®¡
            self.stats["successful_responses"] += 1

            # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
            total_confidence = self.stats.get("total_confidence", 0) + confidence
            self.stats["total_confidence"] = total_confidence
            self.stats["average_confidence"] = total_confidence / self.stats["successful_responses"]

            self.logger.info(f"æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s, ç½®ä¿¡åº¦: {confidence:.1%}")
            return response

        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")

            # è¿”å›é”™è¯¯å“åº”
            return SimpleAgentResponse(
                content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶å‘ç”Ÿäº†é”™è¯¯ï¼š{str(e)}",
                confidence=0.0,
                sources=[],
                task_type="error",
                processing_time=time.time() - start_time,
                model_used="error",
                metadata={"error": str(e)}
            )

    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        # æ£€æŸ¥Ollamaè¿æ¥
        ollama_status = self.ollama_client.test_connection()

        return {
            "ollama": {
                "status": ollama_status["status"],
                "model": self.ollama_client.model_name,
                "available": self.ollama_client.is_available()
            },
            "rag": {
                "enabled": self.rag_system is not None,
                "documents_loaded": len(self.documents) if self.documents else 0,
                "searches_performed": self.stats["rag_searches"]
            },
            "performance": self.stats,
            "ollama_stats": self.ollama_client.get_stats()
        }

    def interactive_mode(self):
        """äº¤äº’æ¨¡å¼"""
        print("ğŸ¤– IoTå®‰å…¨æ™ºèƒ½åŠ©æ‰‹ (Ollamaç‰ˆ)")
        print("=" * 50)
        print("è¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹å¸®åŠ©ï¼Œ'status' æŸ¥çœ‹çŠ¶æ€")

        # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
        status = self.get_system_status()
        if not status["ollama"]["available"]:
            print("âŒ OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨OllamaæœåŠ¡")
            print("å¯åŠ¨å‘½ä»¤: ollama serve")
            return

        print(f"âœ… ç³»ç»Ÿå°±ç»ª - æ¨¡å‹: {status['ollama']['model']}")

        if status["rag"]["enabled"]:
            print(f"ğŸ“š çŸ¥è¯†åº“: {status['rag']['documents_loaded']} ä¸ªæ–‡æ¡£")
        else:
            print("âš ï¸ çŸ¥è¯†åº“æœªåŠ è½½ï¼Œå°†åœ¨åŸºç¡€æ¨¡å¼ä¸‹è¿è¡Œ")

        while True:
            try:
                user_input = input("\nğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()

                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨IoTå®‰å…¨æ™ºèƒ½åŠ©æ‰‹ï¼")
                    break

                if user_input.lower() == 'help':
                    self._show_help()
                    continue

                if user_input.lower() == 'status':
                    self._show_status()
                    continue

                if not user_input:
                    continue

                print("\nğŸ¤” æ­£åœ¨åˆ†æå’Œç”Ÿæˆå›ç­”...")

                # å¤„ç†æŸ¥è¯¢
                response = self.process_query(user_input)

                # æ˜¾ç¤ºå›ç­”
                self._display_response(response)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨IoTå®‰å…¨æ™ºèƒ½åŠ©æ‰‹ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©"""
        help_text = """
ğŸ†˜ IoTå®‰å…¨æ™ºèƒ½åŠ©æ‰‹å¸®åŠ©
===================

ğŸ¯ ä¸»è¦åŠŸèƒ½:
â€¢ CVEæ¼æ´åˆ†æ: "åˆ†æCVE-2023-0001çš„å½±å“"
â€¢ å¨èƒæ£€æµ‹: "IoTè®¾å¤‡å¼‚å¸¸ç½‘ç»œè¡Œä¸ºåˆ†æ"  
â€¢ å®‰å…¨è¯„ä¼°: "è¯„ä¼°æ™ºèƒ½å®¶å±…å®‰å…¨é£é™©"
â€¢ é˜²æŠ¤å»ºè®®: "å¦‚ä½•é˜²æŠ¤IoTè®¾å¤‡DDoSæ”»å‡»"
â€¢ ç ”ç©¶æ€»ç»“: "IoTåŠ å¯†æŠ€æœ¯æœ€æ–°è¿›å±•"

ğŸ’¡ ä½¿ç”¨æŠ€å·§:
â€¢ ä½¿ç”¨å…·ä½“çš„æŠ€æœ¯æœ¯è¯­
â€¢ æè¿°è¯¦ç»†çš„åœºæ™¯ä¿¡æ¯
â€¢ æ”¯æŒä¸­è‹±æ–‡æŸ¥è¯¢
â€¢ å¯ä»¥è¦æ±‚step-by-stepåˆ†æ

ğŸ”§ å‘½ä»¤:
â€¢ help: æ˜¾ç¤ºå¸®åŠ©
â€¢ status: æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€  
â€¢ quit: é€€å‡ºç³»ç»Ÿ

ğŸ“Š ç¤ºä¾‹æŸ¥è¯¢:
â€¢ "ä»€ä¹ˆæ˜¯IoTå®‰å…¨ï¼Ÿ"
â€¢ "æ™ºèƒ½æ‘„åƒå¤´æœ‰å“ªäº›å®‰å…¨æ¼æ´ï¼Ÿ"
â€¢ "å¦‚ä½•ä¿æŠ¤å·¥ä¸šIoTç½‘ç»œï¼Ÿ"
        """
        print(help_text)

    def _show_status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
        status = self.get_system_status()

        print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€")
        print("=" * 30)

        # OllamaçŠ¶æ€
        ollama = status["ollama"]
        print(f"ğŸ¤– Ollama:")
        print(f"  çŠ¶æ€: {'âœ… å¯ç”¨' if ollama['available'] else 'âŒ ä¸å¯ç”¨'}")
        print(f"  æ¨¡å‹: {ollama['model']}")

        # RAGçŠ¶æ€
        rag = status["rag"]
        print(f"ğŸ“š çŸ¥è¯†åº“:")
        print(f"  çŠ¶æ€: {'âœ… å·²åŠ è½½' if rag['enabled'] else 'âŒ æœªåŠ è½½'}")
        print(f"  æ–‡æ¡£æ•°: {rag['documents_loaded']}")
        print(f"  æ£€ç´¢æ¬¡æ•°: {rag['searches_performed']}")

        # æ€§èƒ½ç»Ÿè®¡
        perf = status["performance"]
        print(f"ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ€»æŸ¥è¯¢æ•°: {perf['total_queries']}")
        print(f"  æˆåŠŸå“åº”: {perf['successful_responses']}")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {perf['average_confidence']:.1%}")

        # Ollamaç»Ÿè®¡
        ollama_stats = status["ollama_stats"]
        print(f"ğŸ”§ Ollamaç»Ÿè®¡:")
        for key, value in ollama_stats.items():
            print(f"  {key}: {value}")

    def _display_response(self, response: SimpleAgentResponse):
        """æ˜¾ç¤ºå“åº”"""
        print("\n" + "=" * 80)
        print("ğŸ¤– IoTå®‰å…¨ä¸“å®¶å›ç­”")
        print("=" * 80)

        # æ˜¾ç¤ºå…ƒä¿¡æ¯
        print(f"ğŸ¯ ä»»åŠ¡ç±»å‹: {response.task_type}")
        print(
            f"ğŸ“Š ç½®ä¿¡åº¦: {'â–ˆ' * int(response.confidence * 10)}{'â–‘' * (10 - int(response.confidence * 10))} {response.confidence:.1%}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {response.model_used}")
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {response.processing_time:.2f}s")
        print(f"ğŸ“„ Tokenä½¿ç”¨: {response.metadata.get('tokens_used', 'N/A')}")

        # æ˜¾ç¤ºä¸»è¦å›ç­”
        print(f"\nğŸ“ è¯¦ç»†åˆ†æ:")
        print("-" * 60)
        print(response.content)

        # æ˜¾ç¤ºå‚è€ƒæº
        if response.sources:
            print(f"\nğŸ“š å‚è€ƒæ¥æº ({len(response.sources)} ä¸ª):")
            print("-" * 40)
            for i, source in enumerate(response.sources[:3], 1):
                source_type = "ğŸ“š å­¦æœ¯ç ”ç©¶" if source['type'] == 'academic' else "ğŸš¨ CVEæ¼æ´"
                print(f"{i}. {source_type} [ç›¸å…³åº¦: {source['score']:.3f}]")

                if source['type'] == 'cve' and source.get('cve_id'):
                    print(f"   ğŸ†” CVE ID: {source['cve_id']}")
                elif source['type'] == 'academic' and source.get('research_area'):
                    print(f"   ğŸ“– ç ”ç©¶é¢†åŸŸ: {source['research_area']}")

                print(f"   ğŸ“„ å†…å®¹: {source['preview']}")


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
def demo_simple_agent():
    """æ¼”ç¤ºç®€åŒ–Agent"""
    print("ğŸš€ ç®€åŒ–RAG+Ollama Agentæ¼”ç¤º")
    print("=" * 50)

    # åˆ›å»ºAgent
    config = {
        "model_name": "llama3.1:7b",  # å¯ä»¥æ”¹ä¸ºå…¶ä»–æ¨¡å‹
        "max_tokens": 1500,
        "temperature": 0.7,
        "use_rag": True,
        "rag_top_k": 3
    }

    try:
        agent = SimpleRAGAgent(config)

        # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
        status = agent.get_system_status()
        print(f"ç³»ç»ŸçŠ¶æ€:")
        print(f"  Ollama: {'âœ…' if status['ollama']['available'] else 'âŒ'}")
        print(f"  æ¨¡å‹: {status['ollama']['model']}")
        print(f"  çŸ¥è¯†åº“: {'âœ…' if status['rag']['enabled'] else 'âŒ'}")

        if not status['ollama']['available']:
            print("\nâŒ Ollamaä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡:")
            print("  ollama serve")
            print("  ollama pull llama3.1:7b")
            return

        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯IoTå®‰å…¨ï¼Ÿ",
            "æ™ºèƒ½å®¶å±…è®¾å¤‡æœ‰å“ªäº›å¸¸è§æ¼æ´ï¼Ÿ",
            "å¦‚ä½•é˜²æŠ¤IoTè®¾å¤‡å…å—DDoSæ”»å‡»ï¼Ÿ"
        ]

        print(f"\nğŸ’¬ æµ‹è¯•æŸ¥è¯¢:")
        for query in test_queries:
            print(f"\nğŸ“ æŸ¥è¯¢: {query}")
            print("-" * 50)

            try:
                response = agent.process_query(query)

                print(f"âœ… ä»»åŠ¡ç±»å‹: {response.task_type}")
                print(f"ğŸ“Š ç½®ä¿¡åº¦: {response.confidence:.1%}")
                print(f"â±ï¸ è€—æ—¶: {response.processing_time:.2f}s")
                print(f"ğŸ“š ä½¿ç”¨æº: {len(response.sources)} ä¸ª")

                # æ˜¾ç¤ºå›ç­”é¢„è§ˆ
                preview = response.content[:200] + "..." if len(response.content) > 200 else response.content
                print(f"ğŸ“„ å›ç­”é¢„è§ˆ: {preview}")

            except Exception as e:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

        # å¯åŠ¨äº¤äº’æ¨¡å¼
        print(f"\nğŸ® å¯åŠ¨äº¤äº’æ¨¡å¼...")
        agent.interactive_mode()

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    # è¿è¡Œæ¼”ç¤º
    demo_simple_agent()