# prompt_templates.py - IoTå®‰å…¨é¢†åŸŸæç¤ºæ¨¡æ¿åº“
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import json
import re
from datetime import datetime
from abc import ABC, abstractmethod


class PromptType(Enum):
    """æç¤ºç±»å‹æšä¸¾"""
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    FUNCTION = "function"


class TaskComplexity(Enum):
    """ä»»åŠ¡å¤æ‚åº¦æšä¸¾"""
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    EXPERT = "expert"


@dataclass
class PromptTemplate:
    """æç¤ºæ¨¡æ¿æ•°æ®ç»“æ„"""
    name: str
    description: str
    template: str
    variables: List[str]
    task_type: str
    complexity: TaskComplexity
    examples: List[Dict] = None
    constraints: List[str] = None

    def __post_init__(self):
        if self.examples is None:
            self.examples = []
        if self.constraints is None:
            self.constraints = []


class IoTSecurityPromptLibrary:
    """IoTå®‰å…¨é¢†åŸŸæç¤ºæ¨¡æ¿åº“"""

    def __init__(self):
        self.templates = {}
        self.examples_db = {}
        self._initialize_templates()
        self._initialize_examples()

    def _initialize_templates(self):
        """åˆå§‹åŒ–æç¤ºæ¨¡æ¿"""

        # CVEåˆ†ææ¨¡æ¿
        self.templates["cve_analysis"] = PromptTemplate(
            name="CVEæ¼æ´åˆ†æ",
            description="ä¸“é—¨ç”¨äºåˆ†æCVEæ¼æ´çš„è¯¦ç»†ä¿¡æ¯",
            template="""ä½ æ˜¯ä¸€åä¸“ä¸šçš„IoTå®‰å…¨ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å¯¹CVEæ¼æ´è¿›è¡Œä¸“ä¸šåˆ†æï¼š

## åˆ†æç›®æ ‡
CVE ID: {cve_id}
æ¼æ´æè¿°: {description}
CVSSè¯„åˆ†: {cvss_score}
ä¸¥é‡ç¨‹åº¦: {severity}
å½±å“è®¾å¤‡: {affected_devices}
æ¼æ´ç±»å‹: {vulnerability_types}

## åˆ†æè¦æ±‚
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œåˆ†æï¼š

### 1. æ¼æ´æ¦‚è¿°
- ç®€è¦æè¿°æ¼æ´çš„æœ¬è´¨å’Œè§¦å‘æ¡ä»¶
- è§£é‡ŠæŠ€æœ¯ç»†èŠ‚å’Œæ ¹æœ¬åŸå› 

### 2. å½±å“åˆ†æ
- è¯„ä¼°å¯¹IoTè®¾å¤‡çš„å…·ä½“å½±å“
- åˆ†ææ”»å‡»è€…å¯èƒ½çš„åˆ©ç”¨æ–¹å¼
- ä¼°ç®—å½±å“èŒƒå›´å’Œä¸¥é‡ç¨‹åº¦

### 3. æŠ€æœ¯åˆ†æ
- è¯¦ç»†è§£é‡Šæ¼æ´çš„æŠ€æœ¯æœºåˆ¶
- åˆ†ææ”»å‡»å‘é‡å’Œåˆ©ç”¨è·¯å¾„
- è¯„ä¼°æ”»å‡»å¤æ‚åº¦å’Œå¯æ£€æµ‹æ€§

### 4. é£é™©è¯„ä¼°
- åŸºäºCVSSè¯„åˆ†åˆ†æé£é™©ç­‰çº§
- è€ƒè™‘åœ¨IoTç¯å¢ƒä¸­çš„ç‰¹æ®Šé£é™©
- è¯„ä¼°ä¸šåŠ¡å½±å“å’Œæ•°æ®å®‰å…¨é£é™©

### 5. ç¼“è§£æªæ–½
- æä¾›ç«‹å³å¯æ‰§è¡Œçš„ä¸´æ—¶æªæ–½
- å»ºè®®é•¿æœŸçš„å®‰å…¨æ”¹è¿›æ–¹æ¡ˆ
- ç»™å‡ºæ£€æµ‹å’Œç›‘æ§å»ºè®®

## è¾“å‡ºæ ¼å¼
è¯·ä½¿ç”¨ç»“æ„åŒ–çš„Markdownæ ¼å¼ï¼Œç¡®ä¿å†…å®¹ä¸“ä¸šã€å‡†ç¡®ã€actionableã€‚

## å‚è€ƒä¿¡æ¯
{retrieved_context}
""",
            variables=["cve_id", "description", "cvss_score", "severity", "affected_devices", "vulnerability_types",
                       "retrieved_context"],
            task_type="cve_lookup",
            complexity=TaskComplexity.EXPERT,
            constraints=[
                "å¿…é¡»åŸºäºæŠ€æœ¯äº‹å®è¿›è¡Œåˆ†æ",
                "é¿å…è¿‡åº¦æŠ€æœ¯æœ¯è¯­ï¼Œä¿æŒä¸“ä¸šä½†æ˜“æ‡‚",
                "æä¾›å…·ä½“å¯è¡Œçš„å»ºè®®",
                "ç»“åˆIoTç¯å¢ƒç‰¹ç‚¹è¿›è¡Œåˆ†æ"
            ]
        )

        # å¨èƒæ£€æµ‹æ¨¡æ¿
        self.templates["threat_detection"] = PromptTemplate(
            name="IoTå¨èƒæ£€æµ‹åˆ†æ",
            description="ç”¨äºæ£€æµ‹å’Œåˆ†æIoTç¯å¢ƒä¸­çš„å®‰å…¨å¨èƒ",
            template="""ä½œä¸ºIoTå®‰å…¨å¨èƒåˆ†æä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹å¨èƒè¿›è¡Œå…¨é¢åˆ†æï¼š

## å¨èƒä¿¡æ¯
å¨èƒæè¿°: {threat_description}
ç›®æ ‡ç¯å¢ƒ: {target_environment}
è§‚å¯Ÿåˆ°çš„è¡Œä¸º: {observed_behavior}

## åˆ†ææ¡†æ¶

### 1. å¨èƒè¯†åˆ«
- å¨èƒç±»å‹åˆ†ç±»
- æ”»å‡»æ‰‹æ®µè¯†åˆ«
- å¨èƒæºåˆ†æ

### 2. æ”»å‡»è·¯å¾„åˆ†æ
è¿ç”¨MITRE ATT&CKæ¡†æ¶åˆ†æï¼š
- Initial Access (åˆå§‹è®¿é—®)
- Execution (æ‰§è¡Œ)
- Persistence (æŒä¹…åŒ–)
- Lateral Movement (æ¨ªå‘ç§»åŠ¨)
- Impact (å½±å“)

### 3. IoTç‰¹å®šé£é™©è¯„ä¼°
è€ƒè™‘IoTç¯å¢ƒçš„ç‰¹æ®Šæ€§ï¼š
- è®¾å¤‡èµ„æºé™åˆ¶
- ç½‘ç»œé€šä¿¡ç‰¹ç‚¹
- ç‰©ç†è®¿é—®é£é™©
- å¤§è§„æ¨¡éƒ¨ç½²å½±å“

### 4. æ£€æµ‹ç­–ç•¥
- æŠ€æœ¯æ£€æµ‹æŒ‡æ ‡
- è¡Œä¸ºå¼‚å¸¸æ¨¡å¼
- ç½‘ç»œæµé‡ç‰¹å¾
- è®¾å¤‡çŠ¶æ€ç›‘æ§

### 5. å“åº”å»ºè®®
- å³æ—¶å“åº”æªæ–½
- éš”ç¦»å’Œéåˆ¶ç­–ç•¥
- æ¢å¤å’Œä¿®å¤è®¡åˆ’
- é¢„é˜²å†æ¬¡å‘ç”Ÿçš„æªæ–½

## æ¨ç†è¿‡ç¨‹
è¯·è¯¦ç»†è¯´æ˜ä½ çš„åˆ†ææ€è·¯å’Œåˆ¤æ–­ä¾æ®ã€‚

## å‚è€ƒèµ„æ–™
{retrieved_context}
""",
            variables=["threat_description", "target_environment", "observed_behavior", "retrieved_context"],
            task_type="threat_detection",
            complexity=TaskComplexity.COMPLEX
        )

        # å®‰å…¨è¯„ä¼°æ¨¡æ¿
        self.templates["security_assessment"] = PromptTemplate(
            name="IoTå®‰å…¨è¯„ä¼°",
            description="å¯¹IoTç³»ç»Ÿè¿›è¡Œå…¨é¢çš„å®‰å…¨è¯„ä¼°",
            template="""ä½œä¸ºIoTå®‰å…¨è¯„ä¼°ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹ç³»ç»Ÿè¿›è¡Œä¸“ä¸šçš„å®‰å…¨è¯„ä¼°ï¼š

## è¯„ä¼°å¯¹è±¡
ç³»ç»Ÿç±»å‹: {system_type}
éƒ¨ç½²ç¯å¢ƒ: {deployment_environment}
è®¾å¤‡è§„æ¨¡: {device_scale}
ä¸šåŠ¡å…³é”®æ€§: {business_criticality}

## è¯„ä¼°ç»´åº¦

### 1. è®¾å¤‡å®‰å…¨
- ç¡¬ä»¶å®‰å…¨ç‰¹æ€§
- å›ºä»¶å®‰å…¨æ€§
- èº«ä»½è®¤è¯æœºåˆ¶
- è®¿é—®æ§åˆ¶å®ç°

### 2. é€šä¿¡å®‰å…¨
- æ•°æ®ä¼ è¾“åŠ å¯†
- åè®®å®‰å…¨æ€§
- ç½‘ç»œæ¶æ„å®‰å…¨
- å¯†é’¥ç®¡ç†

### 3. æ•°æ®å®‰å…¨
- æ•°æ®åˆ†ç±»å’Œæ ‡è®°
- å­˜å‚¨å®‰å…¨
- éšç§ä¿æŠ¤
- æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†

### 4. è¿è¥å®‰å…¨
- å®‰å…¨ç›‘æ§èƒ½åŠ›
- äº‹ä»¶å“åº”æœºåˆ¶
- è¡¥ä¸ç®¡ç†æµç¨‹
- ä¾›åº”é“¾å®‰å…¨

### 5. åˆè§„æ€§è¯„ä¼°
- ç›¸å…³æ³•è§„è¦æ±‚
- è¡Œä¸šæ ‡å‡†ç¬¦åˆæ€§
- å®‰å…¨æ¡†æ¶å¯¹æ ‡

## è¯„ä¼°æ–¹æ³•
è¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•è¿›è¡Œè¯„ä¼°ï¼š
1. åŸºäºçŸ¥è¯†åº“çš„æœ€ä½³å®è·µå¯¹æ¯”
2. å¨èƒå»ºæ¨¡å’Œé£é™©åˆ†æ
3. æ§åˆ¶æªæ–½æœ‰æ•ˆæ€§è¯„ä¼°
4. æ®‹ä½™é£é™©è¯„ä¼°

## è¾“å‡ºè¦æ±‚
- é£é™©ç­‰çº§è¯„å®šï¼ˆé«˜/ä¸­/ä½ï¼‰
- å…·ä½“é£é™©æ¸…å•
- ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®
- å®æ–½è·¯çº¿å›¾

## çŸ¥è¯†åº“ä¿¡æ¯
{retrieved_context}
""",
            variables=["system_type", "deployment_environment", "device_scale", "business_criticality",
                       "retrieved_context"],
            task_type="security_assessment",
            complexity=TaskComplexity.COMPLEX
        )

        # é˜²æŠ¤å»ºè®®æ¨¡æ¿
        self.templates["prevention_advice"] = PromptTemplate(
            name="IoTå®‰å…¨é˜²æŠ¤å»ºè®®",
            description="ä¸ºIoTç¯å¢ƒæä¾›ä¸“ä¸šçš„å®‰å…¨é˜²æŠ¤å»ºè®®",
            template="""ä½œä¸ºIoTå®‰å…¨é˜²æŠ¤ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹æƒ…å†µæä¾›ä¸“ä¸šçš„é˜²æŠ¤å»ºè®®ï¼š

## é˜²æŠ¤éœ€æ±‚
å®‰å…¨é—®é¢˜: {security_issue}
é˜²æŠ¤ç›®æ ‡: {protection_target}
ç¯å¢ƒçº¦æŸ: {environment_constraints}
èµ„æºé™åˆ¶: {resource_limitations}

## é˜²æŠ¤ç­–ç•¥æ¡†æ¶

### 1. åˆ†å±‚é˜²æŠ¤ç­–ç•¥
**è®¾å¤‡å±‚é˜²æŠ¤:**
- ç¡¬ä»¶å®‰å…¨æ¨¡å—(HSM)
- å®‰å…¨å¯åŠ¨æœºåˆ¶
- å›ºä»¶å®Œæ•´æ€§ä¿æŠ¤
- è®¾å¤‡èº«ä»½è®¤è¯

**ç½‘ç»œå±‚é˜²æŠ¤:**
- ç½‘ç»œåˆ†æ®µå’Œéš”ç¦»
- æµé‡ç›‘æ§å’Œè¿‡æ»¤
- å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ
- VPNå’ŒåŠ å¯†é€šé“

**åº”ç”¨å±‚é˜²æŠ¤:**
- åº”ç”¨å®‰å…¨å¼€å‘
- APIå®‰å…¨ä¿æŠ¤
- æ•°æ®åŠ å¯†å­˜å‚¨
- è®¿é—®æƒé™æ§åˆ¶

**ç®¡ç†å±‚é˜²æŠ¤:**
- å®‰å…¨ç­–ç•¥åˆ¶å®š
- äººå‘˜å®‰å…¨åŸ¹è®­
- ä¾›åº”é“¾å®‰å…¨ç®¡ç†
- åº”æ€¥å“åº”è®¡åˆ’

### 2. æŠ€æœ¯å®æ–½å»ºè®®
è¯·æä¾›å…·ä½“çš„æŠ€æœ¯å®æ–½æ–¹æ¡ˆï¼š
- æ¨èçš„å®‰å…¨äº§å“å’Œå·¥å…·
- é…ç½®å‚æ•°å’Œéƒ¨ç½²æ–¹æ¡ˆ
- é›†æˆå’Œå…¼å®¹æ€§è€ƒè™‘
- æ€§èƒ½å½±å“è¯„ä¼°

### 3. æˆæœ¬æ•ˆç›Šåˆ†æ
- å®æ–½æˆæœ¬ä¼°ç®—
- é£é™©é™ä½æ•ˆæœ
- ROIåˆ†æ
- åˆ†é˜¶æ®µå®æ–½å»ºè®®

### 4. å®æ–½è·¯çº¿å›¾
- çŸ­æœŸæªæ–½ï¼ˆ1-3ä¸ªæœˆï¼‰
- ä¸­æœŸè§„åˆ’ï¼ˆ3-12ä¸ªæœˆï¼‰
- é•¿æœŸæˆ˜ç•¥ï¼ˆ1-3å¹´ï¼‰
- å…³é”®é‡Œç¨‹ç¢‘

## æœ€ä½³å®è·µå‚è€ƒ
{retrieved_context}
""",
            variables=["security_issue", "protection_target", "environment_constraints", "resource_limitations",
                       "retrieved_context"],
            task_type="prevention_advice",
            complexity=TaskComplexity.MODERATE
        )

        # ç ”ç©¶æ€»ç»“æ¨¡æ¿
        self.templates["research_summary"] = PromptTemplate(
            name="IoTå®‰å…¨ç ”ç©¶æ€»ç»“",
            description="æ€»ç»“IoTå®‰å…¨é¢†åŸŸçš„ç ”ç©¶æˆæœå’Œè¶‹åŠ¿",
            template="""ä½œä¸ºIoTå®‰å…¨ç ”ç©¶ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹ç ”ç©¶ä¸»é¢˜è¿›è¡Œä¸“ä¸šæ€»ç»“ï¼š

## ç ”ç©¶ä¸»é¢˜
ç ”ç©¶é¢†åŸŸ: {research_topic}
æ—¶é—´èŒƒå›´: {time_range}
å…³æ³¨é‡ç‚¹: {focus_areas}

## æ€»ç»“æ¡†æ¶

### 1. ç ”ç©¶æ¦‚è§ˆ
- ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº
- ä¸»è¦ç ”ç©¶é—®é¢˜
- ç ”ç©¶æ–¹æ³•å’Œé€”å¾„

### 2. æ ¸å¿ƒå‘ç°
**æŠ€æœ¯åˆ›æ–°:**
- æ–°æŠ€æœ¯å’Œæ–¹æ³•
- ç®—æ³•å’Œæ¨¡å‹æ”¹è¿›
- å·¥å…·å’Œæ¡†æ¶å‘å±•

**å®è¯ç ”ç©¶:**
- å®éªŒç»“æœå’Œæ•°æ®
- æ€§èƒ½è¯„ä¼°å’Œæ¯”è¾ƒ
- æ¡ˆä¾‹ç ”ç©¶åˆ†æ

**ç†è®ºè´¡çŒ®:**
- ç†è®ºæ¨¡å‹å’Œæ¡†æ¶
- æ¦‚å¿µå®šä¹‰å’Œåˆ†ç±»
- åŸç†æœºåˆ¶è§£é‡Š

### 3. æŠ€æœ¯è¶‹åŠ¿åˆ†æ
- æ–°å…´æŠ€æœ¯æ–¹å‘
- æˆç†ŸæŠ€æœ¯åº”ç”¨
- æŠ€æœ¯èåˆè¶‹åŠ¿
- æ ‡å‡†åŒ–è¿›å±•

### 4. æŒ‘æˆ˜å’Œæœºé‡
**å½“å‰æŒ‘æˆ˜:**
- æŠ€æœ¯å±€é™æ€§
- å®æ–½éšœç¢
- æˆæœ¬å’Œå¤æ‚æ€§é—®é¢˜

**æœªæ¥æœºé‡:**
- æŠ€æœ¯å‘å±•ç©ºé—´
- å¸‚åœºéœ€æ±‚é©±åŠ¨
- æ”¿ç­–æ”¯æŒæ–¹å‘

### 5. å®è·µåº”ç”¨
- å·¥ä¸šåº”ç”¨æ¡ˆä¾‹
- æœ€ä½³å®è·µæ€»ç»“
- å®æ–½ç»éªŒæ•™è®­
- åº”ç”¨å‰æ™¯å±•æœ›

### 6. ç ”ç©¶æ–¹å‘å»ºè®®
- äºŸéœ€è§£å†³çš„é—®é¢˜
- æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘
- è·¨å­¦ç§‘åˆä½œæœºä¼š
- äº§å­¦ç ”ç»“åˆå»ºè®®

## å­¦æœ¯èµ„æ–™å‚è€ƒ
{retrieved_context}
""",
            variables=["research_topic", "time_range", "focus_areas", "retrieved_context"],
            task_type="research_summary",
            complexity=TaskComplexity.EXPERT
        )

        # ä¸€èˆ¬æŸ¥è¯¢æ¨¡æ¿
        self.templates["general_query"] = PromptTemplate(
            name="IoTå®‰å…¨ä¸€èˆ¬æŸ¥è¯¢",
            description="å¤„ç†IoTå®‰å…¨é¢†åŸŸçš„ä¸€èˆ¬æ€§æŸ¥è¯¢",
            template="""ä½œä¸ºIoTå®‰å…¨ä¸“å®¶ï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

## ç”¨æˆ·é—®é¢˜
{user_question}

## å›ç­”è¦æ±‚
è¯·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€å®ç”¨çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š

### 1. ç›´æ¥å›ç­”
- é’ˆå¯¹é—®é¢˜çš„æ ¸å¿ƒå›ç­”
- å…³é”®æ¦‚å¿µå’Œæœ¯è¯­è§£é‡Š
- é‡è¦æ³¨æ„äº‹é¡¹

### 2. æŠ€æœ¯ç»†èŠ‚
- ç›¸å…³æŠ€æœ¯åŸç†
- å®æ–½æ–¹æ³•å’Œæ­¥éª¤
- å·¥å…·å’Œèµ„æºæ¨è

### 3. å®è·µå»ºè®®
- æœ€ä½³å®è·µæŒ‡å¯¼
- å¸¸è§é—®é¢˜é¿å…
- è¿›ä¸€æ­¥å­¦ä¹ èµ„æº

### 4. æ¡ˆä¾‹ä¸¾ä¾‹
- ç›¸å…³åº”ç”¨æ¡ˆä¾‹
- æˆåŠŸç»éªŒåˆ†äº«
- å¤±è´¥æ•™è®­æ€»ç»“

## å›ç­”é£æ ¼
- ä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
- ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€
- æä¾›actionableçš„å»ºè®®
- ç»“åˆæœ€æ–°æŠ€æœ¯å‘å±•

## å‚è€ƒä¿¡æ¯
{retrieved_context}
""",
            variables=["user_question", "retrieved_context"],
            task_type="general_query",
            complexity=TaskComplexity.SIMPLE
        )

    def _initialize_examples(self):
        """åˆå§‹åŒ–Few-shotç¤ºä¾‹åº“"""

        # CVEåˆ†æç¤ºä¾‹
        self.examples_db["cve_analysis"] = [
            {
                "input": {
                    "cve_id": "CVE-2023-0001",
                    "description": "Buffer overflow vulnerability in IoT device firmware",
                    "cvss_score": "7.5",
                    "severity": "High"
                },
                "output": """## CVE-2023-0001 æ¼æ´åˆ†æ

### 1. æ¼æ´æ¦‚è¿°
è¿™æ˜¯ä¸€ä¸ªå½±å“IoTè®¾å¤‡å›ºä»¶çš„ç¼“å†²åŒºæº¢å‡ºæ¼æ´ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡æ„é€ æ¶æ„æ•°æ®åŒ…è§¦å‘æº¢å‡ºï¼Œå¯èƒ½å¯¼è‡´è¿œç¨‹ä»£ç æ‰§è¡Œã€‚

### 2. å½±å“åˆ†æ
- **ç›´æ¥å½±å“**: è®¾å¤‡å®Œå…¨å¤±æ§ï¼Œå¯è¢«è¿œç¨‹æ“ä½œ
- **é—´æ¥å½±å“**: å¯èƒ½æˆä¸ºåƒµå°¸ç½‘ç»œèŠ‚ç‚¹ï¼Œå½±å“ç½‘ç»œå®‰å…¨
- **ä¸šåŠ¡å½±å“**: æœåŠ¡ä¸­æ–­ï¼Œæ•°æ®æ³„éœ²é£é™©

### 3. æŠ€æœ¯åˆ†æ
ç¼“å†²åŒºæº¢å‡ºå‘ç”Ÿåœ¨ç½‘ç»œæ•°æ®åŒ…å¤„ç†æ¨¡å—ï¼Œç”±äºç¼ºä¹è¾¹ç•Œæ£€æŸ¥å¯¼è‡´æ ˆæº¢å‡ºï¼Œæ”»å‡»è€…å¯ä»¥è¦†ç›–è¿”å›åœ°å€å®ç°ä»£ç æ‰§è¡Œã€‚

### 4. é£é™©è¯„ä¼°
CVSS 7.5åˆ†å±äºé«˜é£é™©æ¼æ´ï¼Œåœ¨IoTç¯å¢ƒä¸­é£é™©æ›´é«˜å› ä¸ºï¼š
- è®¾å¤‡é€šå¸¸ç¼ºä¹å®‰å…¨æ›´æ–°æœºåˆ¶
- å¤§è§„æ¨¡éƒ¨ç½²éš¾ä»¥å¿«é€Ÿä¿®å¤
- å¯èƒ½å½±å“å…³é”®åŸºç¡€è®¾æ–½

### 5. ç¼“è§£æªæ–½
**ç«‹å³æªæ–½**:
- éš”ç¦»å—å½±å“è®¾å¤‡
- å®æ–½ç½‘ç»œè®¿é—®æ§åˆ¶
- ç›‘æ§å¼‚å¸¸ç½‘ç»œæµé‡

**é•¿æœŸæªæ–½**:
- éƒ¨ç½²å›ºä»¶æ›´æ–°
- å®æ–½è¾“å…¥éªŒè¯
- å¯ç”¨æ ˆä¿æŠ¤æœºåˆ¶"""
            }
        ]

        # å¨èƒæ£€æµ‹ç¤ºä¾‹
        self.examples_db["threat_detection"] = [
            {
                "input": {
                    "threat_description": "IoTè®¾å¤‡å¼‚å¸¸ç½‘ç»œè¿æ¥",
                    "observed_behavior": "å¤§é‡å¯¹å¤–è¿æ¥ï¼Œæ•°æ®ä¼ è¾“å¼‚å¸¸"
                },
                "output": """## IoTè®¾å¤‡å¼‚å¸¸è¿æ¥å¨èƒåˆ†æ

### 1. å¨èƒè¯†åˆ«
- **å¨èƒç±»å‹**: å¯èƒ½çš„åƒµå°¸ç½‘ç»œæ„ŸæŸ“æˆ–æ•°æ®çªƒå–
- **æ”»å‡»æ‰‹æ®µ**: æ¶æ„è½¯ä»¶æ„ŸæŸ“æˆ–è¿œç¨‹æ§åˆ¶
- **å¨èƒç­‰çº§**: é«˜

### 2. æ”»å‡»è·¯å¾„åˆ†æ
**Initial Access**: åˆ©ç”¨è®¾å¤‡æ¼æ´æˆ–å¼±è®¤è¯
**Execution**: æ¤å…¥æ¶æ„ä»£ç 
**Command and Control**: å»ºç«‹C2é€šä¿¡
**Exfiltration**: æ•°æ®å¤–ä¼ æˆ–å‚ä¸æ”»å‡»

### 3. æ£€æµ‹ç­–ç•¥
- ç›‘æ§ç½‘ç»œæµé‡åŸºçº¿åå·®
- æ£€æµ‹æœªæˆæƒå¤–éƒ¨è¿æ¥
- åˆ†ææ•°æ®ä¼ è¾“æ¨¡å¼å¼‚å¸¸
- ç›‘æ§è®¾å¤‡è¡Œä¸ºå˜åŒ–

### 4. å“åº”å»ºè®®
**ç«‹å³éš”ç¦»**: æ–­å¼€ç½‘ç»œè¿æ¥
**æ·±åº¦åˆ†æ**: æ£€æŸ¥è®¾å¤‡å›ºä»¶å®Œæ•´æ€§
**æ¸…ç†ä¿®å¤**: é‡ç½®è®¾å¤‡æˆ–æ›´æ–°å›ºä»¶
**é¢„é˜²æªæ–½**: åŠ å¼ºç½‘ç»œç›‘æ§å’Œè®¿é—®æ§åˆ¶"""
            }
        ]

    def get_template(self, task_type: str) -> Optional[PromptTemplate]:
        """è·å–æŒ‡å®šä»»åŠ¡ç±»å‹çš„æ¨¡æ¿"""
        return self.templates.get(task_type)

    def get_examples(self, task_type: str, num_examples: int = 2) -> List[Dict]:
        """è·å–æŒ‡å®šä»»åŠ¡ç±»å‹çš„ç¤ºä¾‹"""
        examples = self.examples_db.get(task_type, [])
        return examples[:num_examples]

    def list_templates(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡æ¿"""
        return {name: template.description for name, template in self.templates.items()}


class ChainOfThoughtPromptBuilder:
    """æ€ç»´é“¾æç¤ºæ„å»ºå™¨"""

    def __init__(self):
        self.reasoning_patterns = {
            "analysis": [
                "é¦–å…ˆï¼Œè®©æˆ‘åˆ†æé—®é¢˜çš„æ ¸å¿ƒè¦ç´ ",
                "æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦è€ƒè™‘ç›¸å…³çš„æŠ€æœ¯å› ç´ ",
                "ç„¶åï¼Œæˆ‘å°†è¯„ä¼°æ½œåœ¨çš„é£é™©å’Œå½±å“",
                "æœ€åï¼Œæˆ‘ä¼šæä¾›å…·ä½“çš„å»ºè®®å’Œè§£å†³æ–¹æ¡ˆ"
            ],
            "investigation": [
                "è®©æˆ‘é€æ­¥è°ƒæŸ¥è¿™ä¸ªå®‰å…¨é—®é¢˜",
                "ç¬¬ä¸€æ­¥ï¼šæ”¶é›†å’Œåˆ†æç›¸å…³ä¿¡æ¯",
                "ç¬¬äºŒæ­¥ï¼šè¯†åˆ«å¯èƒ½çš„æ”»å‡»å‘é‡",
                "ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°å¨èƒçš„ä¸¥é‡ç¨‹åº¦",
                "ç¬¬å››æ­¥ï¼šåˆ¶å®šç›¸åº”çš„é˜²æŠ¤æªæ–½"
            ],
            "problem_solving": [
                "è®©æˆ‘ç³»ç»Ÿæ€§åœ°è§£å†³è¿™ä¸ªé—®é¢˜",
                "é—®é¢˜åˆ†è§£ï¼šå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜",
                "æ–¹æ¡ˆè¯„ä¼°ï¼šåˆ†æå„ç§å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ",
                "æœ€ä¼˜é€‰æ‹©ï¼šé€‰æ‹©æœ€é€‚åˆçš„è§£å†³æ–¹æ¡ˆ",
                "å®æ–½è§„åˆ’ï¼šåˆ¶å®šå…·ä½“çš„å®æ–½è®¡åˆ’"
            ]
        }

    def build_cot_prompt(self, base_prompt: str, reasoning_type: str = "analysis") -> str:
        """æ„å»ºæ€ç»´é“¾æç¤º"""
        cot_instruction = f"""
åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ€è€ƒæ­¥éª¤ï¼š

{chr(10).join(f"{i + 1}. {step}" for i, step in enumerate(self.reasoning_patterns.get(reasoning_type, self.reasoning_patterns["analysis"])))}

ç°åœ¨ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°æ€è€ƒæ­¥éª¤æ¥å¤„ç†ä»¥ä¸‹é—®é¢˜ï¼š

{base_prompt}

è¯·åœ¨å›ç­”ä¸­æ˜ç¡®å±•ç¤ºä½ çš„æ¨ç†è¿‡ç¨‹ã€‚
"""
        return cot_instruction

    def build_step_by_step_prompt(self, task_description: str, steps: List[str]) -> str:
        """æ„å»ºåˆ†æ­¥éª¤æç¤º"""
        step_prompt = f"""
è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡ï¼š{task_description}

å…·ä½“æ­¥éª¤ï¼š
{chr(10).join(f"æ­¥éª¤ {i + 1}: {step}" for i, step in enumerate(steps))}

è¯·æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªæ­¥éª¤ï¼Œå¹¶åœ¨å›ç­”ä¸­è¯´æ˜æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œç»“æœã€‚
"""
        return step_prompt


class FewShotPromptBuilder:
    """Few-shotå­¦ä¹ æç¤ºæ„å»ºå™¨"""

    def __init__(self, prompt_library: IoTSecurityPromptLibrary):
        self.prompt_library = prompt_library

    def build_few_shot_prompt(self, task_type: str, user_input: str,
                              num_examples: int = 2) -> str:
        """æ„å»ºfew-shotæç¤º"""

        # è·å–ç¤ºä¾‹
        examples = self.prompt_library.get_examples(task_type, num_examples)

        if not examples:
            return user_input

        # æ„å»ºfew-shotæç¤º
        few_shot_prompt = "ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•å¤„ç†ç±»ä¼¼çš„IoTå®‰å…¨é—®é¢˜ï¼š\n\n"

        for i, example in enumerate(examples, 1):
            few_shot_prompt += f"## ç¤ºä¾‹ {i}\n"
            few_shot_prompt += f"**è¾“å…¥**: {example['input']}\n"
            few_shot_prompt += f"**è¾“å‡º**: {example['output']}\n\n"

        few_shot_prompt += f"ç°åœ¨ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°ç¤ºä¾‹çš„æ ¼å¼å’Œè´¨é‡æ ‡å‡†ï¼Œå¤„ç†ä»¥ä¸‹é—®é¢˜ï¼š\n\n{user_input}"

        return few_shot_prompt


class PromptOptimizer:
    """æç¤ºä¼˜åŒ–å™¨"""

    def __init__(self):
        self.optimization_history = []
        self.performance_metrics = {}

    def optimize_prompt_length(self, prompt: str, max_length: int = 2000) -> str:
        """ä¼˜åŒ–æç¤ºé•¿åº¦"""
        if len(prompt) <= max_length:
            return prompt

        # ä¿ç•™é‡è¦éƒ¨åˆ†ï¼Œå‹ç¼©æ¬¡è¦å†…å®¹
        lines = prompt.split('\n')
        essential_lines = []
        optional_lines = []

        for line in lines:
            if any(keyword in line.lower() for keyword in ['##', '###', 'è¦æ±‚', 'åˆ†æ', 'å»ºè®®']):
                essential_lines.append(line)
            else:
                optional_lines.append(line)

        # å…ˆåŠ å…¥é‡è¦å†…å®¹
        optimized_prompt = '\n'.join(essential_lines)

        # é€æ­¥æ·»åŠ å¯é€‰å†…å®¹
        for line in optional_lines:
            if len(optimized_prompt) + len(line) + 1 <= max_length:
                optimized_prompt += '\n' + line
            else:
                break

        return optimized_prompt

    def add_contextual_constraints(self, prompt: str, constraints: List[str]) -> str:
        """æ·»åŠ ä¸Šä¸‹æ–‡çº¦æŸ"""
        if not constraints:
            return prompt

        constraints_text = "\n## é‡è¦çº¦æŸæ¡ä»¶\n"
        constraints_text += "\n".join(f"- {constraint}" for constraint in constraints)

        return prompt + "\n" + constraints_text

    def enhance_clarity(self, prompt: str) -> str:
        """å¢å¼ºæç¤ºæ¸…æ™°åº¦"""
        # æ·»åŠ ç»“æ„åŒ–æ ‡è®°
        enhanced_prompt = prompt

        # ç¡®ä¿æœ‰æ˜ç¡®çš„ä»»åŠ¡è¯´æ˜
        if "## ä»»åŠ¡ç›®æ ‡" not in enhanced_prompt:
            task_section = "\n## ä»»åŠ¡ç›®æ ‡\nè¯·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€actionableçš„IoTå®‰å…¨åˆ†æå’Œå»ºè®®ã€‚\n"
            enhanced_prompt = task_section + enhanced_prompt

        # ç¡®ä¿æœ‰è¾“å‡ºæ ¼å¼è¦æ±‚
        if "## è¾“å‡ºæ ¼å¼" not in enhanced_prompt:
            format_section = "\n## è¾“å‡ºæ ¼å¼\nè¯·ä½¿ç”¨ç»“æ„åŒ–çš„Markdownæ ¼å¼ï¼ŒåŒ…å«æ¸…æ™°çš„æ ‡é¢˜å’Œè¦ç‚¹ã€‚\n"
            enhanced_prompt += format_section

        return enhanced_prompt


class PromptTemplateManager:
    """æç¤ºæ¨¡æ¿ç®¡ç†å™¨"""

    def __init__(self):
        self.prompt_library = IoTSecurityPromptLibrary()
        self.cot_builder = ChainOfThoughtPromptBuilder()
        self.few_shot_builder = FewShotPromptBuilder(self.prompt_library)
        self.optimizer = PromptOptimizer()

    def generate_prompt(self, task_type: str, user_input: str,
                        context: Dict = None, use_cot: bool = True,
                        use_few_shot: bool = True, num_examples: int = 1) -> str:
        """ç”Ÿæˆå®Œæ•´çš„æç¤º"""

        # è·å–åŸºç¡€æ¨¡æ¿
        template = self.prompt_library.get_template(task_type)
        if not template:
            template = self.prompt_library.get_template("general_query")

        # å‡†å¤‡å˜é‡
        variables = {}
        if context:
            variables.update(context)

        # å¡«å……æ¨¡æ¿å˜é‡
        try:
            base_prompt = template.template.format(**variables)
        except KeyError as e:
            # å¦‚æœå˜é‡ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼
            for var in template.variables:
                if var not in variables:
                    variables[var] = f"[{var}]"
            base_prompt = template.template.format(**variables)

        # åº”ç”¨Few-shotå­¦ä¹ 
        if use_few_shot and num_examples > 0:
            base_prompt = self.few_shot_builder.build_few_shot_prompt(
                task_type, base_prompt, num_examples
            )

        # åº”ç”¨æ€ç»´é“¾
        if use_cot:
            reasoning_type = "analysis" if task_type in ["cve_lookup", "vulnerability_analysis"] else "investigation"
            base_prompt = self.cot_builder.build_cot_prompt(base_prompt, reasoning_type)

        # ä¼˜åŒ–æç¤º
        optimized_prompt = self.optimizer.enhance_clarity(base_prompt)

        # æ·»åŠ çº¦æŸæ¡ä»¶
        if template.constraints:
            optimized_prompt = self.optimizer.add_contextual_constraints(
                optimized_prompt, template.constraints
            )

        # é•¿åº¦ä¼˜åŒ–
        final_prompt = self.optimizer.optimize_prompt_length(optimized_prompt)

        return final_prompt

    def evaluate_prompt_effectiveness(self, prompt: str, response: str,
                                      expected_quality: float) -> Dict:
        """è¯„ä¼°æç¤ºæ•ˆæœ"""
        metrics = {
            "prompt_length": len(prompt),
            "response_length": len(response),
            "structure_score": self._evaluate_structure(response),
            "clarity_score": self._evaluate_clarity(response),
            "completeness_score": self._evaluate_completeness(response)
        }

        metrics["overall_score"] = (
                metrics["structure_score"] * 0.3 +
                metrics["clarity_score"] * 0.3 +
                metrics["completeness_score"] * 0.4
        )

        return metrics

    def _evaluate_structure(self, response: str) -> float:
        """è¯„ä¼°å“åº”ç»“æ„æ€§"""
        # æ£€æŸ¥æ ‡é¢˜æ•°é‡
        headers = len(re.findall(r'^#{1,6}\s', response, re.MULTILINE))
        # æ£€æŸ¥åˆ—è¡¨ä½¿ç”¨
        lists = len(re.findall(r'^\s*[-*+]\s', response, re.MULTILINE))

        structure_score = min((headers * 0.1 + lists * 0.05), 1.0)
        return structure_score

    def _evaluate_clarity(self, response: str) -> float:
        """è¯„ä¼°å“åº”æ¸…æ™°åº¦"""
        # ç®€å•çš„æ¸…æ™°åº¦è¯„ä¼°ï¼šå¥å­é•¿åº¦ã€æ®µè½ç»“æ„ç­‰
        sentences = re.split(r'[.!?]+', response)
        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0

        # ç†æƒ³å¥å­é•¿åº¦çº¦15-25è¯
        clarity_score = max(0, 1 - abs(avg_sentence_length - 20) / 20)
        return clarity_score

    def _evaluate_completeness(self, response: str) -> float:
        """è¯„ä¼°å“åº”å®Œæ•´æ€§"""
        # æ£€æŸ¥å…³é”®éƒ¨åˆ†æ˜¯å¦å­˜åœ¨
        key_elements = [
            "åˆ†æ", "å»ºè®®", "æªæ–½", "é£é™©", "å½±å“"
        ]

        found_elements = sum(1 for element in key_elements if element in response)
        completeness_score = found_elements / len(key_elements)

        return completeness_score

    def get_template_stats(self) -> Dict:
        """è·å–æ¨¡æ¿ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_templates": len(self.prompt_library.templates),
            "templates_by_complexity": {},
            "templates_by_task": {}
        }

        for template in self.prompt_library.templates.values():
            # æŒ‰å¤æ‚åº¦ç»Ÿè®¡
            complexity = template.complexity.value
            stats["templates_by_complexity"][complexity] = \
                stats["templates_by_complexity"].get(complexity, 0) + 1

            # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
            task_type = template.task_type
            stats["templates_by_task"][task_type] = \
                stats["templates_by_task"].get(task_type, 0) + 1

        return stats


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
def demo_prompt_engineering():
    """æ¼”ç¤ºæç¤ºå·¥ç¨‹åŠŸèƒ½"""
    print("ğŸ¨ IoTå®‰å…¨Prompt Engineeringç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)

    # åˆå§‹åŒ–ç®¡ç†å™¨
    manager = PromptTemplateManager()

    # æ¼”ç¤ºä¸åŒç±»å‹çš„æç¤ºç”Ÿæˆ
    test_cases = [
        {
            "task_type": "cve_lookup",
            "user_input": "åˆ†æCVE-2023-0001çš„å®‰å…¨å½±å“",
            "context": {
                "cve_id": "CVE-2023-0001",
                "description": "Buffer overflow in IoT firmware",
                "cvss_score": "7.5",
                "severity": "High",
                "affected_devices": "IoT routers",
                "vulnerability_types": "buffer_overflow",
                "retrieved_context": "ç›¸å…³æŠ€æœ¯æ–‡æ¡£å’Œåˆ†ææŠ¥å‘Š..."
            }
        },
        {
            "task_type": "threat_detection",
            "user_input": "æ£€æµ‹IoTè®¾å¤‡çš„å¼‚å¸¸ç½‘ç»œè¡Œä¸º",
            "context": {
                "threat_description": "è®¾å¤‡é¢‘ç¹å¤–è”",
                "target_environment": "æ™ºèƒ½å®¶å±…",
                "observed_behavior": "å¤§é‡DNSæŸ¥è¯¢å’Œæ•°æ®ä¼ è¾“",
                "retrieved_context": "ç½‘ç»œç›‘æ§æ•°æ®å’Œå¨èƒæƒ…æŠ¥..."
            }
        }
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ” æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['task_type']}")
        print("-" * 40)

        # ç”ŸæˆåŸºç¡€æç¤º
        basic_prompt = manager.generate_prompt(
            task_type=test_case["task_type"],
            user_input=test_case["user_input"],
            context=test_case["context"],
            use_cot=False,
            use_few_shot=False
        )

        # ç”Ÿæˆå¢å¼ºæç¤ºï¼ˆCoT + Few-shotï¼‰
        enhanced_prompt = manager.generate_prompt(
            task_type=test_case["task_type"],
            user_input=test_case["user_input"],
            context=test_case["context"],
            use_cot=True,
            use_few_shot=True,
            num_examples=1
        )

        print(f"ğŸ“ åŸºç¡€æç¤ºé•¿åº¦: {len(basic_prompt)} å­—ç¬¦")
        print(f"âœ¨ å¢å¼ºæç¤ºé•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦")
        print(f"ğŸ“ˆ å¢å¼ºå¹…åº¦: {((len(enhanced_prompt) - len(basic_prompt)) / len(basic_prompt) * 100):.1f}%")

        # æ˜¾ç¤ºæç¤ºé¢„è§ˆ
        print(f"\nğŸ“„ å¢å¼ºæç¤ºé¢„è§ˆ:")
        preview = enhanced_prompt[:300] + "..." if len(enhanced_prompt) > 300 else enhanced_prompt
        print(preview)

    # æ˜¾ç¤ºæ¨¡æ¿ç»Ÿè®¡
    stats = manager.get_template_stats()
    print(f"\nğŸ“Š æ¨¡æ¿åº“ç»Ÿè®¡:")
    print(f"æ€»æ¨¡æ¿æ•°: {stats['total_templates']}")
    print(f"å¤æ‚åº¦åˆ†å¸ƒ: {stats['templates_by_complexity']}")
    print(f"ä»»åŠ¡ç±»å‹åˆ†å¸ƒ: {stats['templates_by_task']}")


# prompt_evaluator.py - æç¤ºè¯„ä¼°ç³»ç»Ÿ
class PromptEvaluator:
    """æç¤ºæ•ˆæœè¯„ä¼°å™¨"""

    def __init__(self):
        self.evaluation_criteria = {
            "clarity": {
                "weight": 0.25,
                "description": "æç¤ºçš„æ¸…æ™°åº¦å’Œæ˜“ç†è§£æ€§"
            },
            "specificity": {
                "weight": 0.25,
                "description": "æç¤ºçš„å…·ä½“æ€§å’Œé’ˆå¯¹æ€§"
            },
            "completeness": {
                "weight": 0.25,
                "description": "æç¤ºçš„å®Œæ•´æ€§å’Œå…¨é¢æ€§"
            },
            "effectiveness": {
                "weight": 0.25,
                "description": "æç¤ºçš„æ•ˆæœå’Œå®ç”¨æ€§"
            }
        }

    def evaluate_prompt_quality(self, prompt: str, task_type: str) -> Dict:
        """è¯„ä¼°æç¤ºè´¨é‡"""
        scores = {}

        # æ¸…æ™°åº¦è¯„ä¼°
        scores["clarity"] = self._evaluate_clarity(prompt)

        # å…·ä½“æ€§è¯„ä¼°
        scores["specificity"] = self._evaluate_specificity(prompt, task_type)

        # å®Œæ•´æ€§è¯„ä¼°
        scores["completeness"] = self._evaluate_completeness(prompt)

        # æ•ˆæœæ€§è¯„ä¼°
        scores["effectiveness"] = self._evaluate_effectiveness(prompt)

        # è®¡ç®—æ€»åˆ†
        total_score = sum(
            scores[criterion] * self.evaluation_criteria[criterion]["weight"]
            for criterion in scores
        )

        return {
            "total_score": total_score,
            "detailed_scores": scores,
            "recommendations": self._generate_improvement_recommendations(scores)
        }

    def _evaluate_clarity(self, prompt: str) -> float:
        """è¯„ä¼°æ¸…æ™°åº¦"""
        clarity_indicators = [
            ("ç»“æ„åŒ–æ ‡é¢˜", len(re.findall(r'^#{1,6}\s', prompt, re.MULTILINE)) > 0),
            ("æ˜ç¡®æŒ‡ä»¤", any(word in prompt for word in ["è¯·", "éœ€è¦", "è¦æ±‚", "åˆ†æ"])),
            ("åˆ†æ­¥éª¤", "æ­¥éª¤" in prompt or "ç¬¬ä¸€" in prompt),
            ("ç¤ºä¾‹è¯´æ˜", "ç¤ºä¾‹" in prompt or "ä¾‹å¦‚" in prompt)
        ]

        clarity_score = sum(indicator[1] for indicator in clarity_indicators) / len(clarity_indicators)
        return clarity_score

    def _evaluate_specificity(self, prompt: str, task_type: str) -> float:
        """è¯„ä¼°å…·ä½“æ€§"""
        task_specific_keywords = {
            "cve_lookup": ["CVE", "æ¼æ´", "CVSS", "å½±å“", "ç¼“è§£"],
            "threat_detection": ["å¨èƒ", "æ”»å‡»", "æ£€æµ‹", "è¡Œä¸º", "å¼‚å¸¸"],
            "security_assessment": ["è¯„ä¼°", "é£é™©", "å®‰å…¨", "æ§åˆ¶", "åˆè§„"],
            "prevention_advice": ["é˜²æŠ¤", "å»ºè®®", "æªæ–½", "ç­–ç•¥", "å®æ–½"]
        }

        keywords = task_specific_keywords.get(task_type, [])
        if not keywords:
            return 0.5  # é»˜è®¤åˆ†æ•°

        found_keywords = sum(1 for keyword in keywords if keyword in prompt)
        specificity_score = found_keywords / len(keywords)

        return min(specificity_score, 1.0)

    def _evaluate_completeness(self, prompt: str) -> float:
        """è¯„ä¼°å®Œæ•´æ€§"""
        essential_components = [
            ("ä»»åŠ¡æè¿°", any(word in prompt for word in ["ä»»åŠ¡", "ç›®æ ‡", "è¦æ±‚"])),
            ("è¾“å…¥ä¿¡æ¯", "{" in prompt and "}" in prompt),
            ("è¾“å‡ºæ ¼å¼", any(word in prompt for word in ["æ ¼å¼", "ç»“æ„", "è¾“å‡º"])),
            ("çº¦æŸæ¡ä»¶", any(word in prompt for word in ["çº¦æŸ", "é™åˆ¶", "æ³¨æ„"])),
            ("å‚è€ƒä¿¡æ¯", any(word in prompt for word in ["å‚è€ƒ", "åŸºäº", "ä¿¡æ¯"]))
        ]

        completeness_score = sum(component[1] for component in essential_components) / len(essential_components)
        return completeness_score

    def _evaluate_effectiveness(self, prompt: str) -> float:
        """è¯„ä¼°æ•ˆæœæ€§"""
        effectiveness_factors = [
            ("actionableæŒ‡ä»¤", any(word in prompt for word in ["å…·ä½“", "è¯¦ç»†", "actionable"])),
            ("ä¸“ä¸šæœ¯è¯­", any(word in prompt for word in ["ä¸“ä¸š", "æŠ€æœ¯", "å®‰å…¨"])),
            ("å®è·µå¯¼å‘", any(word in prompt for word in ["å®æ–½", "åº”ç”¨", "å®è·µ"])),
            ("è´¨é‡è¦æ±‚", any(word in prompt for word in ["å‡†ç¡®", "å¯é ", "æœ‰æ•ˆ"]))
        ]

        effectiveness_score = sum(factor[1] for factor in effectiveness_factors) / len(effectiveness_factors)
        return effectiveness_score

    def _generate_improvement_recommendations(self, scores: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        if scores["clarity"] < 0.7:
            recommendations.append("å¢åŠ ç»“æ„åŒ–æ ‡é¢˜å’Œåˆ†æ­¥éª¤è¯´æ˜")

        if scores["specificity"] < 0.7:
            recommendations.append("æ·»åŠ æ›´å¤šä»»åŠ¡ç‰¹å®šçš„å…³é”®è¯å’Œè¦æ±‚")

        if scores["completeness"] < 0.7:
            recommendations.append("è¡¥å……ç¼ºå¤±çš„ç»„ä»¶ï¼ˆè¾“å‡ºæ ¼å¼ã€çº¦æŸæ¡ä»¶ç­‰ï¼‰")

        if scores["effectiveness"] < 0.7:
            recommendations.append("å¢å¼ºå®è·µå¯¼å‘å’ŒactionableæŒ‡ä»¤")

        return recommendations


# prompt_optimizer_advanced.py - é«˜çº§æç¤ºä¼˜åŒ–å™¨
class AdvancedPromptOptimizer:
    """é«˜çº§æç¤ºä¼˜åŒ–å™¨"""

    def __init__(self):
        self.optimization_strategies = {
            "length_optimization": self._optimize_length,
            "structure_enhancement": self._enhance_structure,
            "clarity_improvement": self._improve_clarity,
            "context_integration": self._integrate_context
        }

    def optimize_prompt(self, prompt: str, optimization_goals: List[str] = None) -> str:
        """ä¼˜åŒ–æç¤º"""
        if optimization_goals is None:
            optimization_goals = list(self.optimization_strategies.keys())

        optimized_prompt = prompt

        for goal in optimization_goals:
            if goal in self.optimization_strategies:
                optimized_prompt = self.optimization_strategies[goal](optimized_prompt)

        return optimized_prompt

    def _optimize_length(self, prompt: str) -> str:
        """ä¼˜åŒ–é•¿åº¦"""
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        lines = [line for line in prompt.split('\n') if line.strip()]

        # åˆå¹¶ç›¸ä¼¼çš„æ®µè½
        optimized_lines = []
        current_section = []

        for line in lines:
            if line.startswith('#') and current_section:
                # æ–°çš„ç« èŠ‚å¼€å§‹ï¼Œå¤„ç†å½“å‰ç« èŠ‚
                if current_section:
                    optimized_lines.extend(self._compress_section(current_section))
                current_section = [line]
            else:
                current_section.append(line)

        # å¤„ç†æœ€åä¸€ä¸ªç« èŠ‚
        if current_section:
            optimized_lines.extend(self._compress_section(current_section))

        return '\n'.join(optimized_lines)

    def _compress_section(self, section_lines: List[str]) -> List[str]:
        """å‹ç¼©ç« èŠ‚å†…å®¹"""
        if len(section_lines) <= 3:
            return section_lines

        # ä¿ç•™æ ‡é¢˜å’Œå…³é”®å†…å®¹
        compressed = [section_lines[0]]  # æ ‡é¢˜

        # åˆå¹¶å†…å®¹è¡Œ
        content_lines = section_lines[1:]
        if content_lines:
            # ä¿ç•™è¦ç‚¹ï¼Œåˆå¹¶æè¿°
            key_points = [line for line in content_lines if line.strip().startswith('-')]
            descriptions = [line for line in content_lines if not line.strip().startswith('-') and line.strip()]

            if descriptions:
                compressed.append(' '.join(descriptions))
            compressed.extend(key_points)

        return compressed

    def _enhance_structure(self, prompt: str) -> str:
        """å¢å¼ºç»“æ„"""
        lines = prompt.split('\n')
        enhanced_lines = []

        current_level = 0
        for line in lines:
            stripped = line.strip()

            if stripped.startswith('#'):
                # æ ‡é¢˜è¡Œ
                level = len(stripped.split()[0])
                if level > current_level + 1:
                    # æ·»åŠ ä¸­é—´çº§åˆ«æ ‡é¢˜
                    for i in range(current_level + 1, level):
                        enhanced_lines.append('#' * i + ' åˆ†æè¦ç‚¹')
                current_level = level
                enhanced_lines.append(line)
            elif stripped.startswith('-') or stripped.startswith('*'):
                # åˆ—è¡¨é¡¹
                enhanced_lines.append(line)
            elif stripped:
                # æ™®é€šå†…å®¹ï¼Œç¡®ä¿é€‚å½“çš„å±‚çº§
                enhanced_lines.append(line)
            else:
                # ç©ºè¡Œ
                enhanced_lines.append(line)

        return '\n'.join(enhanced_lines)

    def _improve_clarity(self, prompt: str) -> str:
        """æ”¹è¿›æ¸…æ™°åº¦"""
        # æ·»åŠ æ˜ç¡®çš„æ“ä½œæŒ‡ä»¤
        clarity_markers = [
            ("è¯·åˆ†æ", "è¯·è¯¦ç»†åˆ†æ"),
            ("éœ€è¦", "éœ€è¦é‡ç‚¹å…³æ³¨"),
            ("åº”è¯¥", "å»ºè®®é‡‡ç”¨"),
            ("å¯ä»¥", "å¯ä»¥è€ƒè™‘")
        ]

        improved_prompt = prompt
        for original, replacement in clarity_markers:
            improved_prompt = improved_prompt.replace(original, replacement)

        # æ·»åŠ ç»“æœæœŸæœ›è¯´æ˜
        if "è¾“å‡ºè¦æ±‚" not in improved_prompt:
            output_requirement = "\n## è¾“å‡ºè¦æ±‚\nè¯·æä¾›ç»“æ„åŒ–ã€ä¸“ä¸šã€actionableçš„åˆ†æç»“æœã€‚\n"
            improved_prompt += output_requirement

        return improved_prompt

    def _integrate_context(self, prompt: str) -> str:
        """æ•´åˆä¸Šä¸‹æ–‡"""
        # ç¡®ä¿ä¸Šä¸‹æ–‡ä¿¡æ¯è¢«æœ‰æ•ˆåˆ©ç”¨
        if "{retrieved_context}" in prompt:
            context_instruction = """
## ä¸Šä¸‹æ–‡ä¿¡æ¯ä½¿ç”¨æŒ‡å¯¼
è¯·å……åˆ†åˆ©ç”¨æä¾›çš„å‚è€ƒä¿¡æ¯ï¼š
- å¼•ç”¨ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚
- ç»“åˆå…·ä½“çš„æ¡ˆä¾‹æ•°æ®
- å¯¹æ¯”ä¸åŒçš„è§‚ç‚¹å’Œæ–¹æ³•
- éªŒè¯åˆ†æç»“è®ºçš„å‡†ç¡®æ€§
"""
            prompt = prompt.replace(
                "{retrieved_context}",
                "{retrieved_context}" + context_instruction
            )

        return prompt


# dynamic_prompt_generator.py - åŠ¨æ€æç¤ºç”Ÿæˆå™¨
class DynamicPromptGenerator:
    """åŠ¨æ€æç¤ºç”Ÿæˆå™¨"""

    def __init__(self, template_manager: PromptTemplateManager):
        self.template_manager = template_manager
        self.user_feedback_history = []
        self.performance_history = []

    def generate_adaptive_prompt(self, task_type: str, user_input: str,
                                 user_context: Dict = None,
                                 performance_history: List[Dict] = None) -> str:
        """ç”Ÿæˆè‡ªé€‚åº”æç¤º"""

        # åˆ†æç”¨æˆ·å†å²åå¥½
        user_preferences = self._analyze_user_preferences(user_context)

        # åŸºäºæ€§èƒ½å†å²è°ƒæ•´ç­–ç•¥
        optimization_strategy = self._determine_optimization_strategy(performance_history)

        # ç”ŸæˆåŸºç¡€æç¤º
        base_prompt = self.template_manager.generate_prompt(
            task_type=task_type,
            user_input=user_input,
            context=user_context,
            use_cot=optimization_strategy.get("use_cot", True),
            use_few_shot=optimization_strategy.get("use_few_shot", True),
            num_examples=optimization_strategy.get("num_examples", 1)
        )

        # åº”ç”¨ç”¨æˆ·åå¥½
        adapted_prompt = self._apply_user_preferences(base_prompt, user_preferences)

        return adapted_prompt

    def _analyze_user_preferences(self, user_context: Dict = None) -> Dict:
        """åˆ†æç”¨æˆ·åå¥½"""
        preferences = {
            "detail_level": "moderate",  # simple, moderate, detailed
            "technical_depth": "moderate",  # basic, moderate, advanced
            "output_format": "structured",  # concise, structured, comprehensive
            "language_style": "professional"  # casual, professional, academic
        }

        if user_context:
            # åŸºäºç”¨æˆ·è§’è‰²è°ƒæ•´åå¥½
            user_role = user_context.get("user_role", "")
            if "researcher" in user_role.lower():
                preferences["technical_depth"] = "advanced"
                preferences["output_format"] = "comprehensive"
            elif "manager" in user_role.lower():
                preferences["detail_level"] = "simple"
                preferences["output_format"] = "concise"

        return preferences

    def _determine_optimization_strategy(self, performance_history: List[Dict] = None) -> Dict:
        """ç¡®å®šä¼˜åŒ–ç­–ç•¥"""
        strategy = {
            "use_cot": True,
            "use_few_shot": True,
            "num_examples": 1
        }

        if performance_history:
            # åŸºäºå†å²æ€§èƒ½è°ƒæ•´ç­–ç•¥
            avg_confidence = sum(h.get("confidence", 0) for h in performance_history) / len(performance_history)

            if avg_confidence < 0.6:
                # ç½®ä¿¡åº¦ä½ï¼Œå¢åŠ few-shotç¤ºä¾‹
                strategy["num_examples"] = 2
                strategy["use_cot"] = True
            elif avg_confidence > 0.85:
                # ç½®ä¿¡åº¦é«˜ï¼Œå¯ä»¥ç®€åŒ–
                strategy["num_examples"] = 0
                strategy["use_cot"] = False

        return strategy

    def _apply_user_preferences(self, prompt: str, preferences: Dict) -> str:
        """åº”ç”¨ç”¨æˆ·åå¥½"""
        adapted_prompt = prompt

        # è°ƒæ•´è¯¦ç»†ç¨‹åº¦
        if preferences.get("detail_level") == "simple":
            adapted_prompt = self._simplify_prompt(adapted_prompt)
        elif preferences.get("detail_level") == "detailed":
            adapted_prompt = self._enhance_detail(adapted_prompt)

        # è°ƒæ•´æŠ€æœ¯æ·±åº¦
        if preferences.get("technical_depth") == "basic":
            adapted_prompt = self._reduce_technical_complexity(adapted_prompt)
        elif preferences.get("technical_depth") == "advanced":
            adapted_prompt = self._increase_technical_depth(adapted_prompt)

        return adapted_prompt

    def _simplify_prompt(self, prompt: str) -> str:
        """ç®€åŒ–æç¤º"""
        # ç§»é™¤è¿‡äºè¯¦ç»†çš„è¯´æ˜
        lines = prompt.split('\n')
        simplified_lines = []

        skip_next = False
        for line in lines:
            if skip_next:
                skip_next = False
                continue

            if "è¯¦ç»†" in line or "å…·ä½“" in line:
                # ç®€åŒ–è¯¦ç»†è¦æ±‚
                simplified_line = line.replace("è¯¦ç»†", "").replace("å…·ä½“", "")
                if simplified_line.strip():
                    simplified_lines.append(simplified_line)
            else:
                simplified_lines.append(line)

        return '\n'.join(simplified_lines)

    def _enhance_detail(self, prompt: str) -> str:
        """å¢å¼ºç»†èŠ‚"""
        # æ·»åŠ æ›´å¤šè¯¦ç»†è¦æ±‚
        enhanced_prompt = prompt

        if "## åˆ†æè¦æ±‚" in enhanced_prompt:
            detail_enhancement = """
### æ·±åº¦åˆ†æè¦æ±‚
- æä¾›è¯¦ç»†çš„æŠ€æœ¯å®ç°ç»†èŠ‚
- åŒ…å«å…·ä½“çš„é…ç½®å‚æ•°å’Œç¤ºä¾‹
- åˆ†æå¤šç§å¯èƒ½çš„åœºæ™¯å’Œå˜åŒ–
- æä¾›å®Œæ•´çš„å‚è€ƒèµ„æ–™é“¾æ¥
"""
            enhanced_prompt = enhanced_prompt.replace(
                "## åˆ†æè¦æ±‚",
                "## åˆ†æè¦æ±‚" + detail_enhancement
            )

        return enhanced_prompt

    def _reduce_technical_complexity(self, prompt: str) -> str:
        """é™ä½æŠ€æœ¯å¤æ‚åº¦"""
        # æ›¿æ¢å¤æ‚æœ¯è¯­
        simplifications = {
            "CVSSè¯„åˆ†": "å®‰å…¨è¯„çº§",
            "æ”»å‡»å‘é‡": "æ”»å‡»æ–¹å¼",
            "æ¼æ´åˆ©ç”¨": "å®‰å…¨é—®é¢˜åˆ©ç”¨",
            "ç¼“è§£æªæ–½": "è§£å†³æ–¹æ¡ˆ"
        }

        simplified_prompt = prompt
        for complex_term, simple_term in simplifications.items():
            simplified_prompt = simplified_prompt.replace(complex_term, simple_term)

        return simplified_prompt

    def _increase_technical_depth(self, prompt: str) -> str:
        """å¢åŠ æŠ€æœ¯æ·±åº¦"""
        # æ·»åŠ é«˜çº§æŠ€æœ¯è¦æ±‚
        technical_enhancement = """
### é«˜çº§æŠ€æœ¯åˆ†æ
- æä¾›åº•å±‚æŠ€æœ¯åŸç†è§£é‡Š
- åŒ…å«ç›¸å…³åè®®å’Œæ ‡å‡†åˆ†æ
- åˆ†æä¸å…¶ä»–å®‰å…¨æœºåˆ¶çš„äº¤äº’
- æä¾›é‡åŒ–çš„é£é™©è¯„ä¼°æ¨¡å‹
"""

        if "## åˆ†æè¦æ±‚" in prompt:
            enhanced_prompt = prompt.replace(
                "## åˆ†æè¦æ±‚",
                "## åˆ†æè¦æ±‚" + technical_enhancement
            )
        else:
            enhanced_prompt = prompt + technical_enhancement

        return enhanced_prompt

    def collect_feedback(self, prompt: str, response: str,
                         user_satisfaction: float, improvement_suggestions: List[str]):
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        feedback = {
            "prompt": prompt,
            "response": response,
            "satisfaction": user_satisfaction,
            "suggestions": improvement_suggestions,
            "timestamp": datetime.now().isoformat()
        }

        self.user_feedback_history.append(feedback)

        # åŸºäºåé¦ˆè°ƒæ•´æ¨¡æ¿
        self._update_templates_based_on_feedback(feedback)

    def _update_templates_based_on_feedback(self, feedback: Dict):
        """åŸºäºåé¦ˆæ›´æ–°æ¨¡æ¿"""
        if feedback["satisfaction"] < 0.6:
            # ä½æ»¡æ„åº¦ï¼Œéœ€è¦æ”¹è¿›
            for suggestion in feedback["suggestions"]:
                if "æ›´ç®€æ´" in suggestion:
                    # ç”¨æˆ·å¸Œæœ›æ›´ç®€æ´çš„è¾“å‡º
                    pass
                elif "æ›´è¯¦ç»†" in suggestion:
                    # ç”¨æˆ·å¸Œæœ›æ›´è¯¦ç»†çš„åˆ†æ
                    pass
                # å¯ä»¥æ ¹æ®å…·ä½“å»ºè®®è°ƒæ•´æ¨¡æ¿


if __name__ == "__main__":
    demo_prompt_engineering()